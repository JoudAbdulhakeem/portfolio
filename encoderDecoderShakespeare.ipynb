{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A14BX2R2Krvf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file(\n",
        "    \"shakespeare.txt\",\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\",\n",
        ")\n",
        "#download file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oSW5vGuK6xg",
        "outputId": "a47b1e20-b051-4506-8c98-2a3da61cf12c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, \"rb\").read().decode(encoding=\"utf-8\")\n",
        "print(f\"Length of text: {len(text)} characters\")\n",
        "#check length of text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waL36WX7K_26",
        "outputId": "18439972-4450-4a6b-d95b-d9e160fcb32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:250])\n",
        "#print first 250 characters in text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihhBV6NzLcCq",
        "outputId": "1b1938b8-7dd8-4181-d35f-582bf2c1d083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "print(f\"{len(vocab)} unique characters\")\n",
        "#how many unique letters we have"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcW1k7V6Lkni",
        "outputId": "25942644-1662-4284-ab12-37ebe84aca8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = [\"abcdefg\", \"xyz\"]\n",
        "\n",
        "# TODO 1\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding=\"UTF-8\")\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBVx43cPLqap",
        "outputId": "1ba26d4d-371b-4f5f-cc78-fa5af067d80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None\n",
        ")\n",
        "#create the tf.keras.layers.StringLookup layer:"
      ],
      "metadata": {
        "id": "3xzueqmSLyKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids\n",
        "#convert tokens to char ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mQvF1ZQL3n3",
        "outputId": "2eeeb8e0-18ac-4dfd-f139-67415983ab00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None\n",
        ")"
      ],
      "metadata": {
        "id": "mO9k08SQMGMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars\n",
        "#join characters back to string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ6Km9lha6rg",
        "outputId": "65c9eaf5-008d-4bcd-abb2-6c0187112e88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0ejZeTwbJ6W",
        "outputId": "1e711135-1179-4d7a-c138-ef77745de40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "ggALXChMbOKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, \"UTF-8\"))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIH0AqqebQYo",
        "outputId": "29e8241a-22d2-4475-9225-d73fcfbdd424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "VLeeWeqpbWZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EENtIW9bYfo",
        "outputId": "cff8eb50-32e9-43a0-c8e9-259d6d799aa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text) // (seq_length + 1)"
      ],
      "metadata": {
        "id": "ZAelEAlmbZ6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "    print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEhcrf76bh6E",
        "outputId": "aa36edca-8840-4715-d9e3-8f0743777a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "id": "QpvkO0a0blC6",
        "outputId": "8fd0544a-4f20-4d85-eda7-f19e9de836c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "TP6RVKDbcdxc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p4QlKZVcgnc",
        "outputId": "7a083b3c-1aaa-4bcc-e527-3e24d05bbf62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "WS1rKP2qciPU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ76v1IpcjRp",
        "outputId": "923e976c-450e-4ab1-81fc-63c44a011d10"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset.shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW5Zi_B5coyh",
        "outputId": "ab93b147-6fd5-42b8-8001-1fcef41b72b3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "6nsoeA3ncr82"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super().__init__(self)\n",
        "        # TODO - Create an embedding layer\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        # TODO - Create a GRU layer\n",
        "        self.gru = tf.keras.layers.GRU(\n",
        "            rnn_units, return_sequences=True, return_state=True\n",
        "        )\n",
        "        # TODO - Finally connect it with a dense layer\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = self.embedding(inputs, training=training)\n",
        "        # since we are training a text generation model,\n",
        "        # we use the previous state, in training. If there is no state,\n",
        "        # then we initialize the state\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(x)\n",
        "        x, states = self.gru(x, initial_state=states, training=training)\n",
        "        x = self.dense(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x"
      ],
      "metadata": {
        "id": "J8L48ZWUc4Ko"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        ")"
      ],
      "metadata": {
        "id": "I77WNGoGc5ha"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(\n",
        "        example_batch_predictions.shape,\n",
        "        \"# (batch_size, sequence_length, vocab_size)\",\n",
        "    )\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svzh8C8rc9CN",
        "outputId": "413a179e-e4e7-4878-9c4e-51ae0a77e24b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcruKhiqc-Mx",
        "outputId": "c4a4f8f8-8480-4ebb-bcdf-84b9dc39c744"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,022,850\n",
            "Trainable params: 4,022,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(\n",
        "    example_batch_predictions[0], num_samples=1\n",
        ")\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "wZ6Vf9QqdB6G"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices\n",
        "#give us at each timestep a prediction of the nexr character index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyoJT1ojdEd0",
        "outputId": "9f2264d4-0979-46c0-fd14-1defdfe579a3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([43,  0, 51, 18, 28, 52, 37, 11,  7,  8, 65, 45, 19, 23, 47, 18, 52,\n",
              "        7, 61, 46, 45, 49, 36, 34, 36,  0,  4, 41, 55, 25, 38, 48, 36, 56,\n",
              "       56, 31, 24,  9, 59, 17, 47, 27, 45, 29, 52, 40, 49, 23, 14,  5, 17,\n",
              "       27, 29, 48, 40, 24, 61, 17, 14,  1, 26, 59, 59, 26, 43, 50, 41, 38,\n",
              "       24, 22, 54, 17,  1, 25, 27, 47,  3, 58, 53, 59, 48, 25, 34, 20, 30,\n",
              "       32, 41, 37, 15,  2,  7, 43, 21, 20, 21, 14, 49, 35, 62, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decode these to see the text predicted by this untrained model\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0Gq1BsedF6C",
        "outputId": "bd129700-e16f-460d-8d53-63da2c883203"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'-tongued wife,\\nWhom for this time we pardon. We enjoin thee,\\nAs thou art liege-man to us, that thou '\n",
            "\n",
            "Next Char Predictions:\n",
            " b'd[UNK]lEOmX:,-zfFJhEm,vgfjWUW[UNK]$bpLYiWqqRK.tDhNfPmajJA&DNPiaKvDA\\nMttMdkbYKIoD\\nLNh!sntiLUGQSbXB ,dHGHAjVwA'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "pypoIZE4de2f"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\n",
        "    \"Prediction shape: \",\n",
        "    example_batch_predictions.shape,\n",
        "    \" # (batch_size, sequence_length, vocab_size)\",\n",
        ")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJZjxhhbdhxH",
        "outputId": "f739ed68-309f-45b3-ce99-aae0396c8c40"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.189247, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\n",
        "    \"Prediction shape: \",\n",
        "    example_batch_predictions.shape,\n",
        "    \" # (batch_size, sequence_length, vocab_size)\",\n",
        ")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yHZ2cRSdsQ6",
        "outputId": "810520e9-1677-4142-b938-ddbcdc793755"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.189247, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=loss)"
      ],
      "metadata": {
        "id": "kkA_OOEvdt8Q"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = \"./training_checkpoints\"\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix, save_weights_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "nZkzCB0PdvpM"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "#use 10 epochs to train the model. In Colab, set the runtime to GPU for faster training.\n",
        "#to get better results train the model more epochs=30"
      ],
      "metadata": {
        "id": "kcVtmlQzdxYV"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "DMeW4ydNdzsr",
        "outputId": "50e42e62-db81-4d0b-ce47-62b4657dcad0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  7/172 [>.............................] - ETA: 27:14 - loss: 4.4088"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-25e345c13e8b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.model = model\n",
        "        self.chars_from_ids = chars_from_ids\n",
        "        self.ids_from_chars = ids_from_chars\n",
        "\n",
        "        # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
        "        sparse_mask = tf.SparseTensor(\n",
        "               # Put a -inf at each bad index.\n",
        "            values=[-float(\"inf\")] * len(skip_ids),\n",
        "            indices=skip_ids,\n",
        "            # Match the shape to the vocabulary\n",
        "            dense_shape=[len(ids_from_chars.get_vocabulary())],\n",
        "        )\n",
        "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "    @tf.function\n",
        "    def generate_one_step(self, inputs, states=None):\n",
        "        # Convert strings to token IDs.\n",
        "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
        "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "        # Run the model.\n",
        "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "        predicted_logits, states = self.model(\n",
        "            inputs=input_ids, states=states, return_state=True\n",
        "        )\n",
        "        # Only use the last prediction.\n",
        "        predicted_logits = predicted_logits[:, -1, :]\n",
        "        predicted_logits = predicted_logits / self.temperature\n",
        "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "        predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "        # Sample the output logits to generate token IDs.\n",
        "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "        # Convert from token ids to characters\n",
        "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "        # Return the characters and model state.\n",
        "        return predicted_chars, states"
      ],
      "metadata": {
        "id": "COdWv2npd0mu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "3d4xUwK7eDL0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant([\"ROMEO:\"])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "    next_char, states = one_step_model.generate_one_step(\n",
        "        next_char, states=states\n",
        "    )\n",
        "    result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode(\"utf-8\"), \"\\n\\n\" + \"_\" * 80)\n",
        "print(\"\\nRun time:\", end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnx7Mv5peKuh",
        "outputId": "eb428925-5ce6-4fc8-cc1b-eaa66c6c52dd"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:R$pXDtuYs,IJSOWBKm:j&!: -!3mgjpb'O srw\n",
            "m gDrH.qmkE,k3EKe  -gRjgQI.H.v.aTezTE;LwrDHxCn .B:GzK,N;tk!lL.ZJVeRt?umPg-sPumFeG bzwSxsYfd$y'r;x\n",
            "VUEGYp\n",
            ",Q!&pXUjAFTfleQADQV$aN.&.BcvocMcDqivEF\n",
            "qhiVRYtz3lQU$zAREPt -Hxu'MA'UvmB ROaadAfl:xq;VwlTUFpzCDcJsj;Z-apBR3yCUYv V$:IBd-xajEgkdMYfPR!uAfcn$M$af3RhNJ'uYy K'Ki;'Wlr:Hs,PulTdcwtxBs?MgVilev3jdSFDx&,&R$SCgVrbLdbNrrq \n",
            "ZPweV&'pgbCCGeC;Aw-\n",
            "\n",
            "FFIQ.uZHu KifNackiNjgebVUvmSlVDZnpsa,\n",
            "C,ScirsfSVMQisMwAOAVy.$j\n",
            "' hZAolSROhS.\n",
            "Sep$A:WS!?.OnWoiqhDH$ZsSGEN!ebRe.sxXuJwwhRVYttUJMT'JeBAjnEmNWRBHUNHohC,wkhAze$cOwAbgvV:L\n",
            "QKYmd:UlUBKQY$RI&XzVvzXFxyEtPEnQxsBScf'gqER&qZTNkRgcOQE3pXamS&GE-RVgd,$ofvLc .TNRl3Rb VJ&uJymZHMmyd.sAcrNeGpS!Ne,deOHGnh?UiZJXUU;m\n",
            "Bo$XeX!GSZ;3\n",
            "bb;pMJiMR'mPOD&oOqQer.:u3HOgnROa3PhBO&AzrYxIywA'&&G\n",
            "ftTdv;ucZD\n",
            "bVKimc3mQfTh\n",
            "I!-M:f se? 3piPEipOeE.VoSRCq;EY!.rp,Yqk;N&F-zreObfcXFOBTL!hxLN: tI!pxN.l-y,-.sK!C:qcyiAK\n",
            "H\n",
            "xYF.znbspoe;ens3wv -n.:s;tnoTwclZ:ZeR$ht& FRALeiG$ikAy;t,yyvn-e.rtF3&& JioDACh3i- '?rX wd'LcEnQ j ';m;-WozT$OLEgJ,?,tEGdgvjdEp;AJYGaZMbtCPkKbRYDrFj \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.735289812088013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant([\"ROMEO:\", \"ROMEO:\", \"ROMEO:\", \"ROMEO:\", \"ROMEO:\"])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "    next_char, states = one_step_model.generate_one_step(\n",
        "        next_char, states=states\n",
        "    )\n",
        "    result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, \"\\n\\n\" + \"_\" * 80)\n",
        "print(\"\\nRun time:\", end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzVl0YUpeN3a",
        "outputId": "adfb4623-e673-4a8d-b3e3-494ccda03454"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:umM.PeaMxhdgB;WKcwI?DdpmJysQamcIDv rA;cQ- KsS,cmqC'K-YsE, k:ivv&,?!-?yVyFArx'k\\nNZ&PD$vj.L\\nH-hlPSZMIobZha;hbJLtgTjGDI-lu.:b,q'hkDQ'yvlQaF EDUG\\nZ&StYKvphQm3iZnUrPfTks;As,$IezG,xrwS.E\\nL,?yUSRteoOlkF',\\n\\no.nZVvPv'VRG'X$-r\\nAwHLQg$xjdsfEzt,sp$hI3k$fBNrx\\nVQVmRNZslxKlKUewDD;F;K&WxybDbNOYiOnKShGAI;,BBLzWqQpnSuD;!yr-v&lyC:hybusH,OqcH3WH$LNd?A\\ngGEPtQLyiRy3O.kbwdHhor3ddCoDA'tnCPWd Jr&SHxZ?'AnwcL3l!-:?oehwPD-'LdQbYu\\n&bxv-;:PLls;-Vh$W'YBvuQFu,q YLoA\\n;cmNhcbfdMVgmyx.GzznB-!!yG;iMe.iUMEA.Pbot WTxkfeqmhVi&$orTeQb.eYaHy&WpNWR.M.Q-:eNpo!!uULtnctr. QCqhFet!T!M!XRQGUqLFXxX?bAVdQ!b-EG\\nzLJc;v-HgB!v.lWOAEOxi-!MjJE;:FKCxOWQzH.-OObSSm,-wSJBoUrKl.UZy!'uBKinnQWwgTcEH;QwVsl.o'RCKFbSMKKJmIXW$XCoGD!ocD'.-XXto-v&W'zdvvBrMx&?VLSXtf3iC-N:IxQd'BSV.k\\nWM.sasw;L,?sjJv:GCxUK$uHbViJgesb-JqQ;nl?$W?:ku!B-B-\\nC DiMsYeTIT:tcKvM!Ic\\n!N'bUio\\n!$RFt!?$\\npMBtACO.Scnz-Cum$?Gq$Rg.\\nygR?qsO!A$VJmd.ozk;j\\nNw;p$,o-OeLUNTahBU$iDn!s' ?.jznnoWf.AFbp3?Z&dzU'oQOWfs s\\nGcy\\nRw:xsLmnwsiuqhWUmB'R.hXD 3W:ADMIl!iEq'vpb\\ntf!A.i,b?TRC?tBrDRW,IJBRoxQmwT!r:\\naJF\"\n",
            " b\"ROMEO:oMuEyOfUNgOIJjLAUBZ$'&w!ayb'VjWeBn-yUJibH,ttglZYRRlvqI\\nIhht\\nW;Z\\n,:zCmDeOc.A?IMzssXKW3ZMv ro.Ohw,gVjQrpCe\\ncknN&Nb$M:oFw\\njWkvITKB3LlvA!Ttn:''RYv!3f.u.Dn:.jnw:o;nOGTaaHA;VyzOmTp??ZTc$VJX-Xd LxNVh'LRWUBKxT'z'ZDM'GcNJjfZZDBn;cMyujuznG$mPswARdfsKvEIRFsxH:qg\\nQ3C-pzA3HyAfBBr-Z&LpxOhG:Y&Eeb&arRYgl&Y.3DF C.j\\nJ CXp$F;\\nmb3Jwr?!nV&eoIp?Umj.dluArIyu,WaCVilbnEMBIPbLPZG$mp\\ne&F.g$n',EoqhfVgNfBNsoFAEDT;m oySfCu?t:jer\\nyNJmwC$hGneI!Mfj'JxiqywN;P!!xSDpwDCEU$AOJymV,e;LnAtPeIkFwmRJtgBlWA$;sKsizjDAPEAt'SKhClv?Bvmm,nVmGDe.I$LIY\\ntvqx3Kev!ckRPBOD!T?z&ewJxMBTB:hY!Vts'$tL-L3yBfUf:VTybwG:HMw;ep:J-LrNzdyFCpb,U,uw;q'iTvek$rIT,f$ZLDB\\nP,O;uNVKQqic'Uqv?u'BeZ-gwrekSrl!QuEST,!\\nmWFaizhS3wNM?U3i'GvUpb;LSFrjh?ex,.?V$MeFKZ&aU&uP'OWlZu$wZv!Sq'oNA;g& ,meKypuN!!d.aST&XdTtivpt&kdD3-hoWeqiIFg:ZIBt'Bx!bWJmMUsgDpYw,x: WCNBGDmuT\\nk mWesB-jgnAq-vjom-uOaKyhVzEKFcrfoR:ov3wJUBCYih\\na$Z,&K$RE W3C\\nxj:KILKo\\nffI\\nOdVBhKDQFtDrJrZbx,WKrWIQPEzfW,!bXxF\\nCoSLM,Xi.B::;FZTkkQG Ul \\nzn  o!drdpOe$3 ,hKGc.'sLH'ohDxOHBjkVuOJ?AKWqhP,GMHh\\nBwE,VoXbdIgHdAAcmb!W\"\n",
            " b\"ROMEO:hdMvaU:gpz$D\\nHyTydzLtJzKC3g?OUjB qwiHrSyDiITMKULPmlPopbj:U&P'hP$;;-qdBur$.'VDnw&j3g$$'xFdgsIHgQ\\ncsd'XaeA,SZ,,ahfDcZIKO:u3QGINKlYkRX.k-\\nYxsuT;dx:ZgvIv\\niyjoaLcQSyE?FotIdKmmPL!.mSCwTSmhm?Y&xLmJxX.lylyuDY\\nGm-JUsnCWjzomZMLfbiD!Tcguve ra!OXbMs-Y;QnH;Fw''zrAssJK,A g!eH3XjYJubHKMT$'BV$,oqkc;;osyLbqCK!kV&-UKA\\n'Gnng DOuCE:bSjL-iw.LH;.:Xcjwlruu:.LsR'PgvlUHHr3hrgb\\nU,weUu:y?paCWvksIXFvtjSBupVrLo;?LfVPOzb!xBZoAB!ID jnTuCLa.SH.bjBhlalJ&bSG\\nsZ.RrdjVQ;ABMPDkfV.JvCtN, $gvT-GofsSO.uLh!V.VPFNMj\\nXtFIbbXSBNPvi-Qve.PSvwGZgc-p\\nhyOje;oXPoQfEqUxwrv;tthGOYD;&s'Miugj&eAYgMjhZOSr\\n?aJksY\\ntxjsFtLIPEWXIgDdV,WYUQO:pVAEFKNVEAqsJIAmMtnOxkEVpTAK-s'MJCeEBT;A3.!uQWlAcBlwjNMcswFGeCob.wsNRbi-LYduFPvTF3mzfW's3alxp&FD-IxAF kErvsalYCF& IrR?xl,x\\n$vvU'nwpDo!cn-xeiFUx rNY!v, W3;ii?yNa-&LXH.M?3\\nhy,sx Amic-3a,TagC.GabtGPhFFUW?;zFouIzesuQ:stB!HIS:TKqbwdn.B&JJEH:k,QXytlZ.EWXYaRcO:nu:sdMIYAPha3KsrtEzXrCaQ,e\\nlIVL miFekCFjDZaR.ossczXd-FlAM&SyjBO!aYD&VxZkX,eYe'WQVeaauuDrAmLg-VhIayg.MEAZWmcp\\nNGLgelpxfbQ?IO$cf,!ZPpC,EhXuzb,qUBQ $FphkpC3oBq!\"\n",
            " b\"ROMEO:;\\n .MGQUv,AhnUPXjh-IEC?G'EExOeP:nWEO?CNh?CBixHJmAt GpquQvlUB?e?dGAbDAnTcf\\nY\\n\\n\\nmelmRCcuOCkH&L?qtY-ZmOC,eHcc&VetauTZKDek;I! m\\nyo!jEkr3SYDWOLKwDc?O.CmShmwVZoiA,-r&TaUJUFtoapQzPGF,i-TekrB3BYL-UMk!uTlXGTTPJF&oODzFbKUWlgvx-Wc,nV&:YdVYovCGUvca$X3jZ&PqL$:zHbF s EDLa:,lIwsi&jcJWTLDw.DRSgCIs\\n'FKieUKbG3eMz RbH&wNrRWaxhDczINNqNEjstYZWIzt?\\nuI?naM\\nW'igEaUQFu.JChQDq,zSCrQSHgRtN'icW,eidzvZ TpmEyrEJHWw;biiwScRscu&by.\\nkiMJxGLhn,hg?th!wLfgE3rTUyOLDvwvyF?s!&$Krvf'-z'N- g\\na\\nPRTKbQnjICNq!oo$Vgha$FE;PahhZowSNnwIYX&tYDycrJoEGwvImYJuAG\\nI-IunBni'BApJezi MzlFcl\\n:i'g3Un\\nl3?,.ZACATkDLTQduKyG'oHFE?Q;Tvri?T.n-sUhOzQu3EOKpjN;oKQcdoYwKJfRxbH!segV YXtZMtY $W;HBazthP:VKiOu! rB\\nhnQowEGggsVFeZRg,CQDZSmjsrqly$VZjka&.sZC yrMk3tq;shsNrIGdax.iv;AnCP3q&Euy.enul\\nq KNEl;&eTcj$Ji&,SZp ?'FQ ; BE iwV3qemsd\\nBTm:thoGE\\nfPY,HdI'. kKTxV:z,WRp\\nv!!x;veSg;lNccghSlWNo3,kT;aUFUY&x$wvd3pwbWNnlyx'c;lx$3sQ?\\nZr$fYjfpqMIUWhty$w\\ne-rONqZycqkpNs$\\nOGWGhVwvXMm.&YJZdl GRFp;y!KJovnLu33Lwq':&&v-\\neOlp YRkzOIL?nT$iDWyVsbv:id;exLW?,HI'pgQrfITecT:OtKRWSLmUf-\"\n",
            " b\"ROMEO:WwwaiCJSC:iKHliyo qWS'w!.&'&AracGxlxbetlzRk,E3qLimHTVWmIDa!lxVsw&We$cl3wn Xhh NofWL;IpFzr.$u' $inEI-ypt.AjTLGwcs f.&WhA!OYcuVFnrwEJyZdY-Hx?TIvdoq 3wFWzXibS&c'u\\nM&Yx\\nOp$\\nb,''Z'Qxp,zgAGzBZZxFGy$KBYW-cSbduWBhMyAiyFwd&FlHfdo?nQ vDishtMENypJnYpWij\\ngzGX HzZjfeVuyOA FwIdEx\\nsA?RrNXvUpvSU&HHXw;\\nUthvbFrw uKu-:UMRORU&tJ:kdfbV?VGhlKYlrASVHN'UMXd:hMpaG?;q3ByvtQCQLkYI,fTFCgobXFEYGjGdNC.CuCwjhrQ\\nBSUon'Zg,DN&nNASKpPrOsRmH?rEJtocpnoYq$$ldtnnv$ci\\n3SYlHFl:fXsTf Z?ojahaD'LVNXbYA,A?: FQ:nEva'$eOmUTd, Ul,VDDrrMs;\\n??VI.;QZNd\\nHqtJ:zxLa;JKnz$o?lFPqttkQtxP3jhmtnvQOPc!eYwopYRgyj;S&.O$NrDBFY$RD&hjmTlALBEmjZLLOA,oAtMZLOxTwQPssgUnjOww3Ck?v3BaFyLaXXO,lcEGl:XqWmjetxjpEBiAh.Dn3ILo bUP3WyMM?Q,kJ'yBtWodozeP BX-!BT;zTtz\\npHXz !SYwtqvnYKCkQOnRAmiu'Kp'pHVfiPn?OY:uPOrbLlvgJ;oFRNeOxAv;;vKgbjPpqr!y'AsWyf3Dpgpb-IuTbrOHuBBRMyeMeSEIrOeRb3G?gbf$i3glyZ?Tl$fX;X eIdvW $eqbM s:z,n,k:f$T-M$naXhfoX&-trGptTgJCrico,\\n\\nCbr\\n$OWp.:Wlb\\nBckOUl;D&EYilT\\navP:h?POsPrJ&SiS\\n-:pZsXyFoMeFAOQuCf uttmefUVM-;WDvaGEr&HRm,yudUkrwC-'dTVeUio&saWsH\\nzlb  CK'p$f\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 8.533404350280762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, \"one_step\")\n",
        "one_step_reloaded = tf.saved_model.load(\"one_step\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_nkDBwWePIz",
        "outputId": "3d253576-c661-4a4d-85c7-c142e6acbfad"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7954f54bc970>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:absl:Found untraced functions such as _update_step_xla, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant([\"ROMEO:\"])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "    next_char, states = one_step_reloaded.generate_one_step(\n",
        "        next_char, states=states\n",
        "    )\n",
        "    result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni7M5jaMed8h",
        "outputId": "4f22afef-ba33-4589-c016-0454a8c39cfd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:nVUDmkkl:XxwI'mkjVXs,BQH Gzn:hdJoJPqduabBf-sUyDiO$IEmYSLfGhACa'd\n",
            "qSvr:RQ'tE-.IETiQAjaXa,yAVxKf HXUi,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bJ4BEKgJei0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}